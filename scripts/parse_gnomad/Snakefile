import os.path
import glob

############################################################################
## GNOMAD PARSING PIPELINE
## This pipeline parses gnomAD variant data, extracting variant frequency,
## sequence context, and coverage.
############################################################################

# configfile: "../config_files/grch37_neutral_config.yml"

# Project root directory
ROOT_DIR = config["rootdir"]

# GNOMAD associated variables
COVERAGE_FILE = os.path.join(ROOT_DIR,config["gnomad"]["COVERAGE_FILE"]) # gnomad coverage files
VCF_DIR = os.path.join(ROOT_DIR,config["gnomad"]["VCF_DIR"]) # gnomad vcf files

# Reference genome associated variables
GENOME_NAME = config["reference"]["GENOME_NAME"] # name of the genome
REF_SEQ = config["reference"]["REF_SEQ"] # genome fasta file

# Set mutation model directory as output directory
OUTPUT_DIR = os.path.join(ROOT_DIR,config["output"]["MUTMOD_OUTPUT_DIR"])

# Some useful wildcards
vcf_wild = glob_wildcards(VCF_DIR + "{samples}.vcf.bgz").samples

# Create outdir
os.makedirs(OUTPUT_DIR, exist_ok=True)

# collect the names of the split coverage files and output their names
def aggregate_coverage(wildcards):
    checkpoint_output_directory = checkpoints.parse_gnomad_coverage.get(**wildcards).output.parsed_coverage
    chrom_vals = sorted(glob_wildcards(os.path.join(checkpoint_output_directory, '{i}.bed.gz')).i)
    return expand(os.path.join(OUTPUT_DIR,"temp_coverage","{i}.bed.gz"),
                               i=chrom_vals)

# Create psudo-rule that enumerates all input targets
rule all:
    input:
        os.path.join(OUTPUT_DIR,'gnomad_all_potential_mutation.bed.gz.tbi')

# step 1: parse gnomAD input files

# Parse out gnomad variants per chromosome
# Note that everything is assumed to be pre-sorted within the variant files
rule parse_gnomad_variants:
    input:
        vcf_file = os.path.join(VCF_DIR,"{vcf_wild}.vcf.bgz")
    output:
        parsed_sub_vcf = temp(os.path.join(OUTPUT_DIR,'{vcf_wild}.txt.gz'))
    shell:
        'perl parse_gnomad_variant.pl {input.vcf_file} | gzip -c > {output.parsed_sub_vcf}'

# Collate intermediate gzipped variant files in lexographic order
rule collate_gnomad_variants:
    input:
        parsed_sub_vcf = expand(os.path.join(OUTPUT_DIR,'{vcf_wild}.txt.gz'), vcf_wild = sorted(vcf_wild))
    output:
        all_vars = os.path.join(OUTPUT_DIR,'gnomad_variant_with_allele_freq.txt.gz')
    shell:
        'cat {input.parsed_sub_vcf} > {output.all_vars}'

# Parse the summary coverage file
# split the chromosomes apart so that they can be merged in lexographic order later
# Note that everything is assumed to be pre-sorted within each chromosome
checkpoint parse_gnomad_coverage:
    input:
        coverage_file = os.path.join(ROOT_DIR,COVERAGE_FILE)
    output:
        parsed_coverage = temp(directory(os.path.join(OUTPUT_DIR,'temp_coverage')))
    shell:
         """
         mkdir -p {output.parsed_coverage}
         perl parse_gnomad_coverage.pl {input.coverage_file} |\
         awk -F "\\t" -v outdir={output.parsed_coverage} '{{print | "gzip >" outdir "/" $1 ".bed.gz"}}'
         """

rule collate_coverage:
    input:
        parsed_coverage = os.path.join(OUTPUT_DIR,'temp_coverage'),
        gathered_coverage = aggregate_coverage
    output:
        collated_coverage = os.path.join(OUTPUT_DIR,'gnomad_coverage.bed.gz')
    shell:
        """
        cat {input.gathered_coverage} > {output.collated_coverage}
        rm {input.gathered_coverage}
        """
        
# First take in a set of single sites from a bed file, then expand it to a 7-mer with the orginal site at the
# center and get the corresponding DNA sequence. Then generate all possible SNPs at that position and convert
# it to a bed file and  append the average sequencing coverage at that site.
# Finally generate a bed file of mutation information with this format:
# C1: chrom
# C2: start
# C3: end
# C4: ref allele
# C5: alt allele
# C6: 7-mer context
# C7: allele frequency (-1: absence of mutation)
# C8: average sequencing coverage
rule extract_mutation_information:
    input:
        parsed_coverage = os.path.join(OUTPUT_DIR,'gnomad_coverage.bed.gz'),
        all_vars = os.path.join(OUTPUT_DIR,'gnomad_variant_with_allele_freq.txt.gz'),
        ref_fa = os.path.join(ROOT_DIR,REF_SEQ)
    output:
        all_mutations = os.path.join(OUTPUT_DIR,'gnomad_all_potential_mutation.bed.gz')
    shell:
        """
	gunzip -c {input.parsed_coverage} | awk 'BEGIN{{OFS="\\t"}}{{a=$2-3; if (a < 0) a = 0; print $1,a,$3+3}}' |\
        bedtools getfasta -fi {input.ref_fa} -bed - -tab -fo - | perl generate_mutation.pl |\
        join --nocheck-order -a 1 -j 1 /dev/fd/0 <(gunzip -c {input.all_vars}) |\
        perl convert_mutation_file_to_bed.pl | awk '{{if (NF == 6) print $$0"\t-1"; else print $$0}}' |\
        intersectBed -a - -b <(gunzip -c {input.parsed_coverage}) -wa -wb -sorted | cut -f1-7,11 |\
        bgzip -c > {output.all_mutations}
        """

rule index_mutation_information:
    input:
        all_mutations = os.path.join(OUTPUT_DIR,'gnomad_all_potential_mutation.bed.gz')
    output:
        mutations_index = os.path.join(OUTPUT_DIR,'gnomad_all_potential_mutation.bed.gz.tbi')
    shell:
        """
        # index file
	tabix {input.all_mutations}
        """
